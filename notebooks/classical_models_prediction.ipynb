{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from utils import calculate_CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hospitalization numbers\n",
    "hosp = pd.read_csv(\"../data/COVID_hosp.csv\")\n",
    "hosp = hosp[hosp['geography'] == 'DE'][['date', 'total']]\n",
    "hosp = hosp.rename(columns={'total': 'hosp'})\n",
    "hosp['date'] = pd.to_datetime(hosp['date'])\n",
    "hosp = hosp.set_index('date', drop=True)\n",
    "# Calculate incidence per 100.000\n",
    "hosp = hosp['hosp'] / (84357 / 100)\n",
    "\n",
    "# Import waste water data (interpolated) to determine time period where waste water data is present\n",
    "virus = pd.read_excel(\"../data/amelag_aggregierte_kurve.xlsx\")\n",
    "virus = virus[[\"datum\", \"loess_vorhersage\"]].dropna()\n",
    "virus = virus.rename(columns={'datum': 'date', 'loess_vorhersage': 'virus'})\n",
    "virus['date'] = pd.to_datetime(virus['date'])\n",
    "virus = virus.set_index('date', drop=True)\n",
    "virus = virus # normalized to whole population\n",
    "hosp_virus = pd.merge(virus, hosp, on='date', how='inner')\n",
    "# Only the time period where waste water data is present\n",
    "df = hosp_virus.iloc[1:] # Account for the one day that gets lost when differentiating\n",
    "# Create hosp_x column with shifted values\n",
    "df['virus'] = df['virus'].shift(periods=7)\n",
    "df = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, method):\n",
    "    \"\"\"\n",
    "    Split a given dataframe into smaller chunks with a constant context and forecast length.\n",
    "    The chunk window is moved forward by a specified shift value.\n",
    "    The forecast part of the first chunk starts at the biggest expected context length,\n",
    "    so that no matter the given context length the forecast parts always have the same indices.\n",
    "    If the last forecast part of a chunk does not have the full forecast length, the chunk is discarded.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame, the dataframe to be split\n",
    "    - context_length: int, the length of the context window\n",
    "    - forecast_length: int, the length of the forecast window\n",
    "    - max_context_length: int, the maximum context length to be used\n",
    "    - shift: int, the value by which the chunk window moves forward\n",
    "\n",
    "    Returns:\n",
    "    - chunks: list of tuples, each tuple contains a context window and its corresponding forecast window\n",
    "    \"\"\"\n",
    "\n",
    "    if method == \"autoarima\":\n",
    "        context_length = 70\n",
    "    else:\n",
    "        context_length = 7\n",
    "            \n",
    "    max_context_length = 70 ## 70 is needed to align prediction windows \n",
    "    forecast_length = 7\n",
    "    shift = 7\n",
    "    chunks = []\n",
    "    end_index = len(df) - forecast_length + 1\n",
    "\n",
    "    # Start splitting the dataframe into chunks\n",
    "    for i in range(max_context_length - context_length, end_index, shift):\n",
    "        # Define start and end indices for the context and forecast windows\n",
    "        context_start = i\n",
    "        context_end = context_start + context_length\n",
    "        forecast_start = context_end\n",
    "        forecast_end = forecast_start + forecast_length\n",
    "\n",
    "        # Check if the forecast window exceeds the dataframe length\n",
    "        if forecast_end <= len(df):\n",
    "            # Extract context and forecast windows\n",
    "            context_window = df.iloc[context_start:context_end]\n",
    "            forecast_window = df.iloc[forecast_start:forecast_end]\n",
    "            chunks.append((context_window, forecast_window))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_forecast_evaluate(train_chunks, method, log=False, ar=True):\n",
    "    \"\"\"\n",
    "    Train a model, forecast, and evaluate MAPE for each chunk.\n",
    "\n",
    "    Parameters:\n",
    "    - train_chunks: list of tuples, each tuple contains a context window and its corresponding forecast window\n",
    "    - method: str, method to use for forecasting ('autoarima' or 'log_linear')\n",
    "    - plot: bool, whether to plot or not (default is False)\n",
    "\n",
    "    Returns:\n",
    "    - average_mape: float, the average Mean Absolute Percentage Error (MAPE) across all chunks\n",
    "    \"\"\"\n",
    "    def transform():\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        context_window['virus'] = scaler.fit_transform(context_window['virus'].values.reshape(-1, 1))\n",
    "        forecast_window['virus'] = scaler.fit_transform(forecast_window['virus'].values.reshape(-1, 1))\n",
    "    \n",
    "    mape_list = []\n",
    "    mae_list = []\n",
    "    \n",
    "    ar_params = []\n",
    "    ma_params = []\n",
    "    exog_params = []\n",
    "    \n",
    "    for i, (context_window, forecast_window) in enumerate(train_chunks):\n",
    "        if log:\n",
    "            context_window = np.log(context_window)\n",
    "            forecast_window = np.log(forecast_window)\n",
    "            \n",
    "        if method == 'autoarima':\n",
    "        \n",
    "            if ar == True:\n",
    "                context_window = context_window['hosp']\n",
    "                model = auto_arima(context_window, seasonal=False, trace=False)\n",
    "                forecast = model.predict(n_periods=len(forecast_window))\n",
    "\n",
    "            if ar == False:\n",
    "\n",
    "                model = auto_arima(context_window['hosp'], seasonal=False, X=pd.DataFrame(context_window['virus']), trace=False)\n",
    "                forecast = model.predict(n_periods=len(forecast_window['hosp']), X=pd.DataFrame(forecast_window['virus']))\n",
    "                params = model.params()\n",
    "                ar_params.append(params.filter(like='ar'))\n",
    "                ma_params.append(params.filter(like='ma'))\n",
    "                exog_params.append(params.filter(like='virus'))\n",
    "        elif method == 'lin_reg':\n",
    "            model = LinearRegression()\n",
    "            # Use indices of context_window as independent variable and context_window as dependent variable\n",
    "            if ar == True:\n",
    "                context_window = context_window['hosp']\n",
    "                model.fit(np.arange(len(context_window)).reshape(-1, 1), context_window)\n",
    "                forecast_indices = np.arange(len(context_window), len(context_window) + len(forecast_window))\n",
    "                forecast = model.predict(forecast_indices.reshape(-1, 1))\n",
    "            elif ar == False:\n",
    "                X = pd.concat([pd.DataFrame(np.arange(1,len(context_window['hosp'])+1).reshape(-1, 1)), context_window['virus'].reset_index(drop=True)],  axis=1)\n",
    "                X.columns = ['days', 'virus']\n",
    "                model.fit(X, context_window['hosp'])\n",
    "                # Predict the values for forecast window indices\n",
    "                forecast_indices = np.arange(len(context_window['hosp'])+1, len(context_window['hosp']) + len(forecast_window['hosp'])+1)\n",
    "                X_test = pd.concat([pd.DataFrame(forecast_indices.reshape(-1, 1)), forecast_window['virus'].reset_index(drop=True)],  axis=1)\n",
    "                X_test.columns = ['days', 'virus']\n",
    "                forecast = model.predict(X_test)\n",
    "\n",
    "        elif method == 'ridge':\n",
    "            model = Ridge(alpha=5)\n",
    "            # Use indices of context_window as independent variable and context_window as dependent variable\n",
    "            if ar == True:\n",
    "                context_window = context_window['hosp']\n",
    "                model.fit(np.arange(len(context_window)).reshape(-1, 1), context_window)\n",
    "                forecast_indices = np.arange(len(context_window), len(context_window) + len(forecast_window))\n",
    "                forecast = model.predict(forecast_indices.reshape(-1, 1))\n",
    "            elif ar == False:\n",
    "                X = pd.concat([pd.DataFrame(np.arange(1,len(context_window['hosp'])+1).reshape(-1, 1)), context_window['virus'].reset_index(drop=True)],  axis=1)\n",
    "                X.columns = ['days', 'virus']\n",
    "                model.fit(X, context_window['hosp'])\n",
    "                # Predict the values for forecast window indices\n",
    "                forecast_indices = np.arange(len(context_window['hosp'])+1, len(context_window['hosp']) + len(forecast_window['hosp'])+1)\n",
    "                X_test = pd.concat([pd.DataFrame(forecast_indices.reshape(-1, 1)), forecast_window['virus'].reset_index(drop=True)],  axis=1)\n",
    "                X_test.columns = ['days', 'virus']\n",
    "                forecast = model.predict(X_test)\n",
    "\n",
    "        if log:\n",
    "            forecast_window = np.exp(forecast_window)    \n",
    "            forecast = np.exp(forecast)\n",
    "       \n",
    "        # Calculate MAPE for the chunk\n",
    "        mape = mean_absolute_percentage_error(forecast_window['hosp'], forecast) * 100\n",
    "        mae = mean_absolute_error(forecast_window['hosp'], forecast) \n",
    "        mape_list.append(mape)\n",
    "        mae_list.append(mae)\n",
    "    \n",
    "        #print(f\"MAPE for Train Chunk {i+1} using {method}: {mape}\")\n",
    "\n",
    "    CI_mape = calculate_CI(mape_list)\n",
    "    CI_mae = calculate_CI(mae_list)\n",
    "    # Calculate average MAPE\n",
    "    average_mape = np.round(np.mean(mape_list),2)\n",
    "    average_mae = np.round(np.mean(mae_list),2)\n",
    "    print(\"Average MAPE using\", method, \":\", average_mape, \"| CI:\", CI_mape,\n",
    "          \"Average MAE using\", method, \":\", average_mae, \"| CI:\",CI_mae)\n",
    "\n",
    "    #if method == 'autoarima' and ar == False:\n",
    "    #    return average_mape, mape_list, ar_params, ma_params, exog_params, model.params()\n",
    "   # else:\n",
    "    return average_mape, CI_mape, mape_list, average_mae,CI_mae, mae_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_reg ar= True\n",
      "Average MAPE using lin_reg : 8.51 | CI: ['7.05', '9.97'] Average MAE using lin_reg : 0.57 | CI: ['0.40', '0.74']\n",
      "lin_reg ar= False\n",
      "Average MAPE using lin_reg : 11.85 | CI: ['8.74', '14.96'] Average MAE using lin_reg : 0.71 | CI: ['0.49', '0.92']\n",
      "ridge ar= True\n",
      "Average MAPE using ridge : 8.1 | CI: ['6.77', '9.43'] Average MAE using ridge : 0.54 | CI: ['0.39', '0.68']\n",
      "ridge ar= False\n",
      "Average MAPE using ridge : 8.1 | CI: ['6.77', '9.43'] Average MAE using ridge : 0.54 | CI: ['0.39', '0.68']\n",
      "autoarima ar= True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m train_chunks \u001b[39m=\u001b[39m split_dataframe(df, method\u001b[39m=\u001b[39mmethod)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(method, \u001b[39m\"\u001b[39m\u001b[39mar=\u001b[39m\u001b[39m\"\u001b[39m, setting)\n\u001b[0;32m---> 11\u001b[0m average_mape,CI_mape, mape_list, average_mae, CI_mae, mae_list \u001b[39m=\u001b[39m train_forecast_evaluate(train_chunks, method\u001b[39m=\u001b[39;49mmethod, log\u001b[39m=\u001b[39;49mlog, ar\u001b[39m=\u001b[39;49mar)\n\u001b[1;32m     12\u001b[0m median_mape \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(np\u001b[39m.\u001b[39mmedian(mape_list),\u001b[39m2\u001b[39m)\n\u001b[1;32m     13\u001b[0m median_mae \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(np\u001b[39m.\u001b[39mmedian(mae_list),\u001b[39m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mtrain_forecast_evaluate\u001b[0;34m(train_chunks, method, log, ar)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m ar \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     context_window \u001b[39m=\u001b[39m context_window[\u001b[39m'\u001b[39m\u001b[39mhosp\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 34\u001b[0m     model \u001b[39m=\u001b[39m auto_arima(context_window, seasonal\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, trace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     35\u001b[0m     forecast \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(n_periods\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(forecast_window))\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m ar \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pmdarima/arima/auto.py:717\u001b[0m, in \u001b[0;36mauto_arima\u001b[0;34m(y, X, start_p, d, start_q, max_p, max_d, max_q, start_P, D, start_Q, max_P, max_D, max_Q, max_order, m, seasonal, stationary, information_criterion, alpha, test, seasonal_test, stepwise, n_jobs, start_params, trend, method, maxiter, offset_test_args, seasonal_test_args, suppress_warnings, error_action, trace, random, random_state, n_fits, return_valid_fits, out_of_sample_size, scoring, scoring_args, with_intercept, sarimax_kwargs, **fit_args)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[39m# init the stepwise model wrapper\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     search \u001b[39m=\u001b[39m solvers\u001b[39m.\u001b[39m_StepwiseFitWrapper(\n\u001b[1;32m    687\u001b[0m         y,\n\u001b[1;32m    688\u001b[0m         X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msarimax_kwargs,\n\u001b[1;32m    715\u001b[0m     )\n\u001b[0;32m--> 717\u001b[0m sorted_res \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39;49msolve()\n\u001b[1;32m    718\u001b[0m \u001b[39mreturn\u001b[39;00m _return_wrapper(sorted_res, return_valid_fits, start, trace)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pmdarima/arima/_auto_solvers.py:430\u001b[0m, in \u001b[0;36m_StepwiseFitWrapper.solve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m     p \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    426\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[39mif\u001b[39;00m q \u001b[39m<\u001b[39m max_q \u001b[39mand\u001b[39;00m p \u001b[39m<\u001b[39m max_p \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    429\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_k \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m--> 430\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_fit((p \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, d, q \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), (P, D, Q, m)):\n\u001b[1;32m    431\u001b[0m     q \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    432\u001b[0m     p \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pmdarima/arima/_auto_solvers.py:233\u001b[0m, in \u001b[0;36m_StepwiseFitWrapper._do_fit\u001b[0;34m(self, order, seasonal_order, constant)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m (order, seasonal_order, constant) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults_dict:\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m     \u001b[39m# increment the number of fits\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 233\u001b[0m     fit, fit_time, new_ic \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_arima(\n\u001b[1;32m    234\u001b[0m         order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m    235\u001b[0m         seasonal_order\u001b[39m=\u001b[39;49mseasonal_order,\n\u001b[1;32m    236\u001b[0m         with_intercept\u001b[39m=\u001b[39;49mconstant)\n\u001b[1;32m    238\u001b[0m     \u001b[39m# use the orders as a key to be hashed for\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[39m# the dictionary (pointing to fit)\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults_dict[(order, seasonal_order, constant)] \u001b[39m=\u001b[39m fit\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pmdarima/arima/_auto_solvers.py:506\u001b[0m, in \u001b[0;36m_fit_candidate_model\u001b[0;34m(y, X, order, seasonal_order, start_params, trend, method, maxiter, fit_params, suppress_warnings, trace, error_action, out_of_sample_size, scoring, scoring_args, with_intercept, information_criterion, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m fit \u001b[39m=\u001b[39m ARIMA(order\u001b[39m=\u001b[39morder, seasonal_order\u001b[39m=\u001b[39mseasonal_order,\n\u001b[1;32m    499\u001b[0m             start_params\u001b[39m=\u001b[39mstart_params, trend\u001b[39m=\u001b[39mtrend, method\u001b[39m=\u001b[39mmethod,\n\u001b[1;32m    500\u001b[0m             maxiter\u001b[39m=\u001b[39mmaxiter, suppress_warnings\u001b[39m=\u001b[39msuppress_warnings,\n\u001b[1;32m    501\u001b[0m             out_of_sample_size\u001b[39m=\u001b[39mout_of_sample_size, scoring\u001b[39m=\u001b[39mscoring,\n\u001b[1;32m    502\u001b[0m             scoring_args\u001b[39m=\u001b[39mscoring_args,\n\u001b[1;32m    503\u001b[0m             with_intercept\u001b[39m=\u001b[39mwith_intercept, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    505\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m     fit\u001b[39m.\u001b[39;49mfit(y, X\u001b[39m=\u001b[39;49mX, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    508\u001b[0m \u001b[39m# for non-stationarity errors or singular matrices, return None\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39mexcept\u001b[39;00m (LinAlgError, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m v:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pmdarima/arima/arima.py:597\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[0;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[1;32m    594\u001b[0m         X \u001b[39m=\u001b[39m safe_indexing(X, \u001b[39mslice\u001b[39m(\u001b[39m0\u001b[39m, n_exog \u001b[39m-\u001b[39m cv))\n\u001b[1;32m    596\u001b[0m \u001b[39m# Internal call\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(y, X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args)\n\u001b[1;32m    599\u001b[0m \u001b[39m# now make a forecast if we're validating to compute the\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39m# out-of-sample score\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[39mif\u001b[39;00m cv_samples \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m     \u001b[39m# get the predictions (use self.predict, which calls forecast\u001b[39;00m\n\u001b[1;32m    603\u001b[0m     \u001b[39m# from statsmodels internally)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pmdarima/arima/arima.py:518\u001b[0m, in \u001b[0;36mARIMA._fit\u001b[0;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings(record\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    517\u001b[0m         warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 518\u001b[0m         fit, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marima_res_ \u001b[39m=\u001b[39m _fit_wrapper()\n\u001b[1;32m    519\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     fit, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marima_res_ \u001b[39m=\u001b[39m _fit_wrapper()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pmdarima/arima/arima.py:508\u001b[0m, in \u001b[0;36mARIMA._fit.<locals>._fit_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[39m# kwargs that might be in fit args, but if not we override the\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[39m# defaults\u001b[39;00m\n\u001b[1;32m    506\u001b[0m disp \u001b[39m=\u001b[39m fit_args\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 508\u001b[0m \u001b[39mreturn\u001b[39;00m arima, arima\u001b[39m.\u001b[39;49mfit(start_params\u001b[39m=\u001b[39;49mstart_params,\n\u001b[1;32m    509\u001b[0m                         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    510\u001b[0m                         maxiter\u001b[39m=\u001b[39;49m_maxiter,\n\u001b[1;32m    511\u001b[0m                         disp\u001b[39m=\u001b[39;49mdisp,\n\u001b[1;32m    512\u001b[0m                         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/statespace/mlemodel.py:704\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[0;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m         flags[\u001b[39m'\u001b[39m\u001b[39mhessian_method\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m optim_hessian\n\u001b[1;32m    703\u001b[0m     fargs \u001b[39m=\u001b[39m (flags,)\n\u001b[0;32m--> 704\u001b[0m     mlefit \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(MLEModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(start_params, method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    705\u001b[0m                                        fargs\u001b[39m=\u001b[39;49mfargs,\n\u001b[1;32m    706\u001b[0m                                        maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[1;32m    707\u001b[0m                                        full_output\u001b[39m=\u001b[39;49mfull_output,\n\u001b[1;32m    708\u001b[0m                                        disp\u001b[39m=\u001b[39;49mdisp, callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    709\u001b[0m                                        skip_hessian\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    711\u001b[0m \u001b[39m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39mif\u001b[39;00m return_params:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:563\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[39mdel\u001b[39;00m kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_t\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    562\u001b[0m optimizer \u001b[39m=\u001b[39m Optimizer()\n\u001b[0;32m--> 563\u001b[0m xopt, retvals, optim_settings \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49m_fit(f, score, start_params,\n\u001b[1;32m    564\u001b[0m                                                fargs, kwargs,\n\u001b[1;32m    565\u001b[0m                                                hessian\u001b[39m=\u001b[39;49mhess,\n\u001b[1;32m    566\u001b[0m                                                method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    567\u001b[0m                                                disp\u001b[39m=\u001b[39;49mdisp,\n\u001b[1;32m    568\u001b[0m                                                maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[1;32m    569\u001b[0m                                                callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    570\u001b[0m                                                retall\u001b[39m=\u001b[39;49mretall,\n\u001b[1;32m    571\u001b[0m                                                full_output\u001b[39m=\u001b[39;49mfull_output)\n\u001b[1;32m    572\u001b[0m \u001b[39m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[1;32m    573\u001b[0m optim_settings\u001b[39m.\u001b[39mupdate(kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:241\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[0;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[1;32m    238\u001b[0m     fit_funcs\u001b[39m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[1;32m    240\u001b[0m func \u001b[39m=\u001b[39m fit_funcs[method]\n\u001b[0;32m--> 241\u001b[0m xopt, retvals \u001b[39m=\u001b[39m func(objective, gradient, start_params, fargs, kwargs,\n\u001b[1;32m    242\u001b[0m                      disp\u001b[39m=\u001b[39;49mdisp, maxiter\u001b[39m=\u001b[39;49mmaxiter, callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    243\u001b[0m                      retall\u001b[39m=\u001b[39;49mretall, full_output\u001b[39m=\u001b[39;49mfull_output,\n\u001b[1;32m    244\u001b[0m                      hess\u001b[39m=\u001b[39;49mhessian)\n\u001b[1;32m    246\u001b[0m optim_settings \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m: method, \u001b[39m'\u001b[39m\u001b[39mstart_params\u001b[39m\u001b[39m'\u001b[39m: start_params,\n\u001b[1;32m    247\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m'\u001b[39m: maxiter, \u001b[39m'\u001b[39m\u001b[39mfull_output\u001b[39m\u001b[39m'\u001b[39m: full_output,\n\u001b[1;32m    248\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m: disp, \u001b[39m'\u001b[39m\u001b[39mfargs\u001b[39m\u001b[39m'\u001b[39m: fargs, \u001b[39m'\u001b[39m\u001b[39mcallback\u001b[39m\u001b[39m'\u001b[39m: callback,\n\u001b[1;32m    249\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mretall\u001b[39m\u001b[39m'\u001b[39m: retall, \u001b[39m\"\u001b[39m\u001b[39mextra_fit_funcs\u001b[39m\u001b[39m\"\u001b[39m: extra_fit_funcs}\n\u001b[1;32m    250\u001b[0m optim_settings\u001b[39m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/statsmodels/base/optimizer.py:651\u001b[0m, in \u001b[0;36m_fit_lbfgs\u001b[0;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[39melif\u001b[39;00m approx_grad:\n\u001b[1;32m    649\u001b[0m     func \u001b[39m=\u001b[39m f\n\u001b[0;32m--> 651\u001b[0m retvals \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mfmin_l_bfgs_b(func, start_params, maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[1;32m    652\u001b[0m                                  callback\u001b[39m=\u001b[39;49mcallback, args\u001b[39m=\u001b[39;49mfargs,\n\u001b[1;32m    653\u001b[0m                                  bounds\u001b[39m=\u001b[39;49mbounds, disp\u001b[39m=\u001b[39;49mdisp,\n\u001b[1;32m    654\u001b[0m                                  \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kwargs)\n\u001b[1;32m    656\u001b[0m \u001b[39mif\u001b[39;00m full_output:\n\u001b[1;32m    657\u001b[0m     xopt, fopt, d \u001b[39m=\u001b[39m retvals\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:199\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    187\u001b[0m callback \u001b[39m=\u001b[39m _wrap_callback(callback)\n\u001b[1;32m    188\u001b[0m opts \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m: disp,\n\u001b[1;32m    189\u001b[0m         \u001b[39m'\u001b[39m\u001b[39miprint\u001b[39m\u001b[39m'\u001b[39m: iprint,\n\u001b[1;32m    190\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmaxcor\u001b[39m\u001b[39m'\u001b[39m: m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcallback\u001b[39m\u001b[39m'\u001b[39m: callback,\n\u001b[1;32m    197\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmaxls\u001b[39m\u001b[39m'\u001b[39m: maxls}\n\u001b[0;32m--> 199\u001b[0m res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args\u001b[39m=\u001b[39;49margs, jac\u001b[39m=\u001b[39;49mjac, bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    200\u001b[0m                        \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopts)\n\u001b[1;32m    201\u001b[0m d \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mgrad\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mjac\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    202\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    203\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mfuncalls\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mnfev\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    204\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mnit\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mnit\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    205\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mwarnflag\u001b[39m\u001b[39m'\u001b[39m: res[\u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m    206\u001b[0m f \u001b[39m=\u001b[39m res[\u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    359\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    366\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    367\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:286\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[0;32m--> 286\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_grad\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated:\n\u001b[0;32m--> 256\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_grad_impl()\n\u001b[1;32m    257\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun()\n\u001b[1;32m    172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg \u001b[39m=\u001b[39m approx_derivative(fun_wrapped, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx, f0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf,\n\u001b[1;32m    174\u001b[0m                            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfinite_diff_options)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     use_one_sided \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m sparsity \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[1;32m    506\u001b[0m                              use_one_sided, method)\n\u001b[1;32m    507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(sparsity) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(sparsity) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    574\u001b[0m     x \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n\u001b[1;32m    575\u001b[0m     dx \u001b[39m=\u001b[39m x[i] \u001b[39m-\u001b[39m x0[i]  \u001b[39m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[0;32m--> 576\u001b[0m     df \u001b[39m=\u001b[39m fun(x) \u001b[39m-\u001b[39m f0\n\u001b[1;32m    577\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m3-point\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m use_one_sided[i]:\n\u001b[1;32m    578\u001b[0m     x1 \u001b[39m=\u001b[39m x0 \u001b[39m+\u001b[39m h_vecs[i]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun_wrapped\u001b[39m(x):\n\u001b[0;32m--> 456\u001b[0m     f \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_1d(fun(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    457\u001b[0m     \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    458\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`fun` return value has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m                            \u001b[39m\"\u001b[39m\u001b[39mmore than 1 dimension.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:531\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[0;34m(params, *args)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(params, \u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 531\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloglike(params, \u001b[39m*\u001b[39;49margs) \u001b[39m/\u001b[39m nobs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/statespace/mlemodel.py:939\u001b[0m, in \u001b[0;36mMLEModel.loglike\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[39mif\u001b[39;00m complex_step:\n\u001b[1;32m    937\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minversion_method\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m INVERT_UNIVARIATE \u001b[39m|\u001b[39m SOLVE_LU\n\u001b[0;32m--> 939\u001b[0m loglike \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mssm\u001b[39m.\u001b[39;49mloglike(complex_step\u001b[39m=\u001b[39;49mcomplex_step, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    941\u001b[0m \u001b[39m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[39m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[39m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[39mreturn\u001b[39;00m loglike\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/statespace/kalman_filter.py:983\u001b[0m, in \u001b[0;36mKalmanFilter.loglike\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[39mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[1;32m    969\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[39m    The joint loglikelihood.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    981\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mconserve_memory\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    982\u001b[0m                   MEMORY_CONSERVE \u001b[39m^\u001b[39m MEMORY_NO_LIKELIHOOD)\n\u001b[0;32m--> 983\u001b[0m kfilter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_filter(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    984\u001b[0m loglikelihood_burn \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mloglikelihood_burn\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    985\u001b[0m                                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloglikelihood_burn)\n\u001b[1;32m    986\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (kwargs[\u001b[39m'\u001b[39m\u001b[39mconserve_memory\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m&\u001b[39m MEMORY_NO_LIKELIHOOD):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/statespace/kalman_filter.py:903\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[0;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[1;32m    900\u001b[0m kfilter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kalman_filters[prefix]\n\u001b[1;32m    902\u001b[0m \u001b[39m# Initialize the state\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize_state(prefix\u001b[39m=\u001b[39;49mprefix, complex_step\u001b[39m=\u001b[39;49mcomplex_step)\n\u001b[1;32m    905\u001b[0m \u001b[39m# Run the filter\u001b[39;00m\n\u001b[1;32m    906\u001b[0m kfilter()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/statespace/representation.py:983\u001b[0m, in \u001b[0;36mRepresentation._initialize_state\u001b[0;34m(self, prefix, complex_step)\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialization\u001b[39m.\u001b[39minitialized:\n\u001b[1;32m    982\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInitialization is incomplete.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 983\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_statespaces[prefix]\u001b[39m.\u001b[39;49minitialize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialization,\n\u001b[1;32m    984\u001b[0m                                          complex_step\u001b[39m=\u001b[39;49mcomplex_step)\n\u001b[1;32m    985\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mStatespace model not initialized.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for met in [\"lin_reg\", \"ridge\", \"autoarima\"]:\n",
    "    for setting in [True, False]:\n",
    "        log = True\n",
    "        method = met\n",
    "        ar = setting\n",
    "\n",
    "        output_name_metrics = \"../output/\"+method+\"_\"+str(setting)+\"_metrics.csv\"\n",
    "        output_name_summary = \"../output/\"+method+\"_\"+str(setting)+\"_summary.csv\"\n",
    "        train_chunks = split_dataframe(df, method=method)\n",
    "        print(method, \"ar=\", setting)\n",
    "        average_mape,CI_mape, mape_list, average_mae, CI_mae, mae_list = train_forecast_evaluate(train_chunks, method=method, log=log, ar=ar)\n",
    "        median_mape = np.round(np.median(mape_list),2)\n",
    "        median_mae = np.round(np.median(mae_list),2)\n",
    "        metrics = pd.DataFrame({\"MAPE\":mape_list, \"MAE\":mae_list})\n",
    "        summary = pd.DataFrame({\"Mean_MAPE\":average_mape, \"Median_MAPE\":median_mape, \"CI_low_MAPE\":CI_mape[0],\"CI_up_MAPE\":CI_mape[1], \n",
    "                                        \"Mean_MAE\": average_mae, \"Median_MAE\":median_mae, \"CI_low_MAE\":CI_mae[0],\"CI_up_MAE\":CI_mae[1] }, index=[0])\n",
    "        metrics.to_csv(output_name_metrics,index=False)\n",
    "        summary.to_csv(output_name_summary,index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f23ace84943ce80e250d3e34fbae8e2514d638635126369f891a764c405e7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
